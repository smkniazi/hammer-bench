#
#   Licensed to the Apache Software Foundation (ASF) under one or more
#   contributor license agreements.  See the NOTICE file distributed with
#   this work for additional information regarding copyright ownership.
#   The ASF licenses this file to You under the Apache License, Version 2.0
#   (the "License"); you may not use this file except in compliance with
#   the License.  You may obtain a copy of the License at
#
#       http://www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#   distributed under the License is distributed on an "AS IS" BASIS,
#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#   See the License for the specific language governing permissions and
#   limitations under the License.



#|=========================================================================
#|                                                          Benchmark Types
#|                                                          ...............
#|
#|Supported Types = RAW, INTERLEAVED, and BR benchmarks
#|for RAW Bench mark set benchmark.type=RAW
#|and set the raw.* properties
#|
#|for INTERLEAVED Bench mark set 
#|benchmark.type=RAW
#|
#|Filesystems supported are HopsFS, HDFS, CephFS, MapR-FS
#|_________________________________________________________________________
benchmark.type=RAW
benchmark.filesystem.name=HopsFS
#dont forget to change the DFS Client Parameters accordingly for different 
#filesystems


#|=========================================================================
#|                                              WarmUp Phase Configurations
#|                                              ...........................
#|increate the wait time if you are writing more files
#|_________________________________________________________________________
# "files.to.create.in.warmup.phase" is per thread value
files.to.create.in.warmup.phase=10
warmup.phase.wait.time=600000



#|=========================================================================
#|                                                  Raw bechmark properties
#|                                                  .......................
#|Long.MAX_VALUE = 922337236854775807
#|all times are in ms
#|_________________________________________________________________________
raw.create.phase.max.files.to.create=922337236854775807
raw.mkdir.phase.duration=20000
raw.create.files.phase.duration=20000
raw.file.append.phase.duration=20000
#raw.read.files.phase.duration=20000
#raw.ls.dirs.phase.duration=20000
#raw.ls.files.phase.duration=20000
#raw.rename.files.phase.duration=20000
#raw.delete.files.phase.duration=20000
#raw.chmod.files.phase.duration=20000
#raw.chmod.dirs.phase.duration=20000
#raw.file.setReplication.phase.duration=20000
#raw.file.getInfo.phase.duration=20000
#raw.dir.getInfo.phase.duration=20000
#raw.file.change.user.phase.duration=20000
#raw.dir.change.user.phase.duration=20000



#|=========================================================================
#|                                          Interleaved bechmark properties
#|                                          ...............................
#|all parameters are integer values 
#|representing percentages of operations
#|only two decimal places is supported. all should add to 100.00
#|_________________________________________________________________________
generate.percentiles=false


#
#Spotify Workload
#
interleaved.workload.name=Spotify
interleaved.bm.duration=15000
#add block percentage added to create.files. 
interleaved.create.files.percentage=2.7
interleaved.file.append.percentage=0
interleaved.read.files.percentage=68.73
interleaved.rename.files.percentage=1.3
interleaved.ls.dirs.percentage=8.52
interleaved.ls.files.percentage=0.49
interleaved.delete.files.percentage=0.75
interleaved.chmod.files.percentage=0.02
interleaved.chmod.dirs.percentage=0.01
interleaved.mkdir.percentage=0.02
interleaved.file.setReplication.percentage=0.14
interleaved.file.getInfo.percentage=13.04
interleaved.dir.getInfo.percentage=3.96   
interleaved.file.change.user.percentage=0.0
interleaved.dir.change.user.percentage=0.32  




#|=========================================================================
#|                                       BlockReporting bechmark properties
#|                                          ...............................
#|all parameters are integer values
#|_________________________________________________________________________
br.benchmark.duration=60000
br.blocks.per.report=20000
br.blocks.per.file=10
br.files.per.dir=100
br.max.block.size=16
br.min.time.before.nextreport=0
br.max.time.before.nextreport=0
br.skip.creations=false
br.persist.database=jdbc:mysql://salman2.sics.se:3307/hop_salman?user=hop&password=hop

#|=========================================================================
#|                                                  General file properties
#|                                                  .......................
#|file size is bytes
#|_________________________________________________________________________
replication.factor=1
append.size=0
file.size=32768


#
#file tree depth and width parameters
#
dir.per.dir=2
files.per.dir=16

#if enable.fixed.depth.tree is set then the dir.per.dir and files.per.dir 
#parameters will be ignored and a tree of constant depth will be created
#set the depth >= 3
#
#if depth = 3 then
#  dir path =  /test/_user_UUID/hops_dir0
#  file path = /test/_user_UUID/hops_dir0/fileX
#if depth = 5 then
#  dir path =  /test/_user_UUID/added_depth_3/added_depth_4/hops_dirX  
#  file path = /test/_user_UUID/added_depth_3/added_depth_4/hops_dir0/hops_file_X

enable.fixed.depth.tree=false
tree.depth=3


#|=========================================================================
#|                                                     Slave configurations
#|                                                     ....................
#|_________________________________________________________________________
num.slave.threads=33
slave.listening.port=32000

#|=========================================================================
#|                                                          Failover Testing 
#|                                                          ................
#|_________________________________________________________________________
test.failover=false
restart.a.namenode.after=30000
failover.test.start.time=30000
failover.test.duration=240000
hadoop.user=nzo

#HDFS
#failover.namenodes=cloud5.sics.se,cloud6.sics.se
#hadoop.sbin=/tmp/ref/apache_hadoop_distro/hadoop-2.0.4-alpha/sbin
#failover.nn.restart.commands=ssh HADOOP_USER@NAMENODE killall java, ssh HADOOP_USER@NAMENODE HADOOP_SBIN/hadoop-daemon.sh start namenode,ssh HADOOP_USER@NAMENODE HADOOP_SBIN/hadoop-daemon.sh start zkfc

$HopsFS
failover.namenodes=bbc1,cloud5,cloud6,cloud9,cloud11 
hadoop.sbin=/tmp/nzo/hopsfs/sbin
failover.nn.restart.commands=ssh HADOOP_USER@NAMENODE killall java,ssh HADOOP_USER@NAMENODE HADOOP_SBIN/hadoop-daemon.sh start namenode


#|=========================================================================
#|                                                               Test files
#|                                                               ..........
#|_________________________________________________________________________
#"base.dir" this where where the files are created in the hdfs
base.dir=/test
#this is where the results are stored on the local filesystem
results.dir=/tmp/hops-bm-master-results/



#|=========================================================================
#|                                                    Master configurations
#|                                                    .....................
#|_________________________________________________________________________
master.listening.port=4444
#list.of.slaves=bbc2  bbc3 bbc4 bbc5 bbc6 bbc7
list.of.slaves=bbc2  bbc3 bbc4 bbc5 bbc6 bbc7



#|=========================================================================
#|                                                           Remote logging
#|                                                           .............. 
#|_________________________________________________________________________
skip.all.prompt=true
enable.remote.logging=true
remote.logging.port=32001
max.slave.failure.threshold=2


#|=========================================================================
#|                                                    DFS Client Parameters
#|                                                    ..................... 
#|_________________________________________________________________________
//values: ceph:///, maprfs:///, hdfs://mycluster, hdfs://host:port
fs.defaultFS=hdfs://bbc7:26801

#HDFS specific

dfs.ha.namenodes.mycluster=nn1,nn2
dfs.nameservices=mycluster
dfs.namenode.rpc-address.mycluster.nn1=cloud5.sics.se:11001
dfs.namenode.rpc-address.mycluster.nn2=cloud6.sics.se:11001
dfs.client.failover.proxy.provider.mycluster=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider


#HOPS-FS spcecific properties. Theses properties have no effect on HDFS 
dfs.namenode.selector-policy=RANDOM_STICKY
dsf.client.refresh.namenode.list=10000
dfs.clinet.max.retires.on.failure=5
dsf.client.initial.wait.on.retry=100

#CephFS
fs.ceph.impl=org.apache.hadoop.fs.ceph.CephFileSystem
ceph.auth.keyring=/etc/ceph/ceph.client.admin.keyring
ceph.conf.file=/etc/ceph/ceph.conf
ceph.root.dir=/
ceph.mon.address=193.10.66.136:6789
ceph.auth.id=admin

#|=========================================================================
#|                                                         Result Generator
#|                                                         ................ 
#| each result file will contain the namenode count and ndb
#| information used if multiple results are aggregated
#|_________________________________________________________________________
no.of.namenodes=1
no.of.ndb.datanodes=4
